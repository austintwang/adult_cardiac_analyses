import os
import json
from snakemake.utils import min_version

min_version("6.6.1")

configfile: 
    "config/config.yaml"

samples = []
with open("config/samples.tsv") as sample_file:
    h = sample_file.readline().rstrip('\n').split('\t')
    series_ind = h.index("Series")
    samples_rna = []
    for line in sample_file:
        if line.startswith("#"):
            continue
        entries = line.rstrip('\n').split('\t')
        series = entries[series_ind]
        samples.append(series)

# with open("config/rna_cluster_names.txt") as f:
#     rna_cluster_names = []
#     for line in f:
#         rna_cluster_names.append(line.rstrip("\n"))
        
workdir: 
    config['workdir']

max_threads = config["max_threads_per_rule"]

# def script_path(script_name):
#     return str(workflow.source_path(script_name))

include:
    "rules/atac.smk"
include:
    "rules/rna.smk"

rule all:
    """
    Generate all outputs (default)
    """
    input: 
        "results_merged/atac/archr_init",
        # "results_merged/atac/archr_label",
        # "export/atac/embeddings/harmony.tsv.gz",
        # "export/atac/embeddings/umap.tsv.gz",
        # "export/atac/labels/cell_types.tsv.gz",
        # "export/atac/markers",
        # "export/atac/metadata.tsv.gz",
        # "export/atac/figures.tar.gz",
        # "export/atac/datasets.txt",
        # "results_merged/rna/seurat_name_rna/proj.rds",
        # "export/rna/embeddings/harmony.tsv.gz",
        # "export/rna/embeddings/umap.tsv.gz",
        # "export/rna/labels/cell_types.tsv.gz",
        # "export/rna/markers",
        # "export/rna/metadata.tsv.gz",
        # "export/rna/figures.tar.gz",
        # "export/rna/datasets.txt"

rule download_gtf:
    """
    Download GTF data
    """
    output:
        "results_merged/fetch/GRCh38.gtf.gz"
    params:
        url = config["gtf"]
    conda:
        "envs/fetch.yaml"
    shell:
        "curl --no-progress-meter -L {params.url} > {output}"

def get_series(w):
    x = w.sample
    return x.split("-")[0]

def get_replicate(w):
    x = w.sample
    return x.split("-")[1]


rule query_fragments:
    """
    Query ENCODE portal for fragments URL
    """
    output:
        "results/{sample}/fetch/fragments_url.txt"
    params:
        series = get_series,
        replicate = 1,
        dcc_mode = config["dcc_mode"],
        dcc_api_key = os.environ["DCC_API_KEY"], 
        dcc_secret_key = os.environ["DCC_SECRET_KEY"]
    log:
        directory("logs/{sample}/query_fragments")
    conda:
        "envs/fetch.yaml"
    script:
        "scripts/get_fragments_url.py"

rule download_fragments:
    """
    Download fragments tarball
    """
    input:
        "results/{sample}/fetch/fragments_url.txt"
    output:
        "results/{sample}/fetch/fragments.tar.gz"
    params:
        usr = os.environ["DCC_API_KEY"],
        pwd = os.environ["DCC_SECRET_KEY"]
    conda:
        "envs/fetch.yaml"
    shell:
        # "curl --no-progress-meter -L -u {params.usr}:{params.pwd} $(< {input}) > {output}"
        "curl --no-progress-meter -L $(< {input}) > {output}"

rule extract_fragments:
    """
    Extract fragments file from tarball
    """
    input:
        "results/{sample}/fetch/fragments.tar.gz"
    output:
        directory("results/{sample}/fetch/fragments_extracted")
    conda:
        "envs/fetch.yaml"
    shell:
        "mkdir -p {output}; "
        "tar -xzf {input} --transform='s/.*\///' -C {output}"

rule move_fragments:
    """
    Move fragments data to final location
    """
    input:
        "results/{sample}/fetch/fragments_extracted"
    output:
        frag = "results/{sample}/fetch/fragments.tsv.gz",
        frag_ind = "results/{sample}/fetch/fragments.tsv.gz.tbi"
    conda:
        "envs/fetch.yaml"
    shell:
        "cp {input}/fragments.tsv.gz {output.frag}; "
        "cp {input}/fragments.tsv.gz.tbi {output.frag_ind};"

rule query_expression:
    """
    Query ENCODE portal for gene expression matrix URL
    """
    output:
        "results/{sample}/fetch/expression_url.txt"
    params:
        series = get_series,
        replicate = 1,
        dcc_mode = config["dcc_mode"],
        dcc_api_key = os.environ["DCC_API_KEY"], 
        dcc_secret_key = os.environ["DCC_SECRET_KEY"]
    log:
        directory("logs/{sample}/query_fragments")
    conda:
        "envs/fetch.yaml"
    script:
        "scripts/get_expression_url.py"

rule download_expression:
    """
    Download expression tarball
    """
    input:
        "results/{sample}/fetch/expression_url.txt"
    output:
        "results/{sample}/fetch/expression.tar.gz"
    params:
        usr = os.environ["DCC_API_KEY"],
        pwd = os.environ["DCC_SECRET_KEY"]
    conda:
        "envs/fetch.yaml"
    shell:
        # "curl --no-progress-meter -L -u {params.usr}:{params.pwd} $(< {input}) > {output}"
        "curl --no-progress-meter -L $(< {input}) > {output}"

rule extract_expression:
    """
    Extract expression data from tarball
    """
    input:
        "results/{sample}/fetch/expression.tar.gz"
    output:
        directory("results/{sample}/fetch/expression_extracted")
    conda:
        "envs/fetch.yaml"
    shell:
        "mkdir -p {output}; "
        "tar -xzf {input} --transform='s/.*\///' -C {output}"

rule move_expression:
    """
    Move expression data files to final location
    """
    input:
        "results/{sample}/fetch/expression_extracted"
    output:
        matrix = "results/{sample}/fetch/matrix.mtx",
        features = "results/{sample}/fetch/features.tsv",
        barcodes = "results/{sample}/fetch/barcodes.tsv",
    conda:
        "envs/fetch.yaml"
    shell:
        "cp {input}/matrix.mtx {output.matrix}; "
        "cp {input}/features.tsv {output.features}; "
        "cp {input}/barcodes.tsv {output.barcodes};"

rule download_rna_ref_counts:
    """
    Download reference expression tarball
    """
    output:
        "reference/fetch/expression.zip"
    params:
        url = config["rna_ref_counts"]
    conda:
        "envs/fetch.yaml"
    shell:
        "curl --no-progress-meter -L '{params.url}' > {output}"

rule extract_rna_ref_counts:
    """
    Extract reference expression data from tarball
    """
    input:
        "reference/fetch/expression.zip"
    output:
        matrix = "reference/fetch/matrix.mtx",
        features = "reference/fetch/features.tsv",
        barcodes = "reference/fetch/barcodes.tsv",
    conda:
        "envs/fetch.yaml"
    shell:
        "unzip -p {input} rawData_human/countTable_human/matrix.mtx.gz | zcat > {output.matrix}; "
        "unzip -p {input} rawData_human/countTable_human/features.tsv.gz | zcat > {output.features}; "
        "unzip -p {input} rawData_human/countTable_human/barcodes.tsv.gz | zcat > {output.barcodes} "

rule download_rna_ref_metadata:
    """
    Download reference metadata
    """
    output:
        "reference/fetch/metadata.csv"
    params:
        url = config["rna_ref_metadata"]
    conda:
        "envs/fetch.yaml"
    shell:
        "curl --no-progress-meter -L '{params.url}' > {output}"

rule download_barcode_wl:
    """
    Download barcode whitelist
    """
    output:
        rna = "whitelists/rna.txt",
        atac = "whitelists/atac.txt"
    params:
        url_rna = config["bc_wl_rna"],
        url_atac = config["bc_wl_atac"],
    conda:
        "envs/fetch.yaml"
    shell:
        "curl --no-progress-meter -L '{params.url_rna}' | zcat -f > {output.rna}; "
        "curl --no-progress-meter -L '{params.url_atac}' | zcat -f > {output.atac}"